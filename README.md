# ğŸ“ Quiz Generator Flow - CrewAI Multi-Agent System

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)](https://www.python.org/)
[![CrewAI](https://img.shields.io/badge/CrewAI-0.177.0%2B-green.svg)](https://crewai.com)
[![MLflow](https://img.shields.io/badge/MLflow-3.3.2%2B-orange.svg)](https://mlflow.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

Benvenuto nel **Quiz Generator Flow**, un sistema avanzato di generazione automatizzata di quiz educativi basato su [CrewAI](https://crewai.com). Questo progetto implementa un **multi-agent AI system** che utilizza tecniche di **Retrieval-Augmented Generation (RAG)**, **vector databases** e **MLflow tracking** per creare quiz intelligenti e personalizzati per certificazioni tecniche.

## ğŸš€ Caratteristiche Principali

- ğŸ¤– **CrewAI Flow Architecture**: Sistema multi-agente orchestrato con flow sequenziali
- ğŸ” **RAG-Powered Generation**: Generazione domande basata su knowledge base vettoriale
- ğŸ“Š **MLflow Integration**: Tracking esperimenti e valutazione automatica con LLM Judge
- ğŸ—„ï¸ **Qdrant Vector Database**: Database vettoriale per ricerca semantica avanzata
- ğŸ“„ **Multi-format Output**: Quiz in Markdown e PDF, separati per versioni vuote e completate
- ğŸ¯ **Certification-Specific**: Supporto per Azure AI-900, AI-102, Databricks e altre
- ğŸ§ª **Quality Assurance**: Test automatizzati e valutazione qualitÃ  quiz
- ğŸ“ˆ **Performance Analytics**: Metriche dettagliate su rilevanza, fedeltÃ  e correttezza

## ğŸ—ï¸ Architettura del Sistema

Il sistema Ã¨ organizzato in **5 Crews specializzati** che collaborano attraverso un **QuizGeneratorFlow**:

```
ğŸ”„ QuizGeneratorFlow
â”œâ”€â”€ ğŸ“ collect_user_input()          # Input utente e configurazione
â”œâ”€â”€ ğŸ—„ï¸ initialize_vector_database()  # Setup knowledge base Qdrant
â”œâ”€â”€ ğŸ“‹ generate_quiz_template()      # Creazione template dinamici
â”œâ”€â”€ ğŸ” generate_quiz_with_rag_crew() # Generazione domande con RAG
â”œâ”€â”€ ğŸ› ï¸ create_final_quiz()          # Assemblaggio quiz finale
â””â”€â”€ âœ… finalize_flow()              # Summary e cleanup
```

### ğŸ‘¥ Crews Specializzati

- **ğŸ” RagCrew**: Ricerca contestuale e generazione domande
- **ğŸ“‹ TemplateGeneratorCrew**: Creazione template quiz personalizzati  
- **ğŸ› ï¸ QuizMakerCrew**: Assemblaggio quiz finale con popolamento template
- **ğŸ“ QuizTakerCrew**: Simulazione studente per completamento quiz
- **ğŸ“Š QuizEvaluatorCrew**: Valutazione automatica qualitÃ  e metriche

## ğŸ“‹ Prerequisiti

- **Python**: >=3.10, <3.14
- **UV Package Manager**: Per gestione dipendenze ottimizzata
- **Docker**: Per Qdrant vector database
- **Azure OpenAI**: Account e API key per LLM e embedding

## ğŸ”§ Installazione

### 1. **Setup Ambiente**

```bash
# Clone del repository
git clone <repository-url>
cd FGBS_academy/quiz_generator

# Installazione UV (se non presente)
pip install uv

# Installazione dipendenze con CrewAI CLI
crewai install

# Alternativa con UV
uv sync
```

### 2. **Configurazione Environment**

Crea il file `.env` nella root del progetto:

```bash
# Azure OpenAI Configuration
AZURE_OPENAI_API_KEY=your_api_key_here
AZURE_OPENAI_API_VERSION=2025-01-01-preview
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/
MODEL=gpt-4o
EMB_MODEL_NAME=text-embedding-ada-002

# Qdrant Vector Database
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=optional_api_key

# MLflow Tracking Server
MLFLOW_TRACKING_URI=http://127.0.0.1:5001
```

### 3. **Setup Infrastruttura**

```bash
# Avvia Qdrant Vector Database
docker run -p 6333:6333 -v $(pwd)/qdrant_storage:/qdrant/storage qdrant/qdrant

# Avvia MLflow Tracking Server (in terminale separato)
mlflow server --host 127.0.0.1 --port 5001
```

## ğŸš€ ModalitÃ  di Esecuzione

Il sistema supporta **due modalitÃ  principali** di esecuzione controllate dalla funzione `kickoff()` in `main.py`:

### ğŸ“ **ModalitÃ  1: Generazione Quiz Completa**

**Obiettivo**: Eseguire il flow completo di generazione quiz

**Configurazione** in `main.py`:
```python
def kickoff():
    """Alternative entry point for the flow (CrewAI convention)."""
    plot()
    main()          # âœ… Decommenta questa riga
    #evaluation_flow()  # âŒ Commenta questa riga
```

**Comando esecuzione**:
```bash
cd quiz_generator
crewai flow kickoff
```

**Flow eseguito**:
1. âœ… Raccolta input utente (provider, certificazione, topic)
2. âœ… Inizializzazione database vettoriale Qdrant
3. âœ… Generazione template quiz personalizzato
4. âœ… Ricerca RAG e generazione domande JSON
5. âœ… Assemblaggio quiz finale e conversione PDF
6. âœ… Summary e lista file generati

**Output**:
```
outputs/
â”œâ”€â”€ AI_102_document_intelligence_template.md    # Template
â”œâ”€â”€ AI_102_document_intelligence_questions.json # Domande JSON
â”œâ”€â”€ AI_102_document_intelligence_quiz.md        # Quiz vuoto
â””â”€â”€ AI_102_document_intelligence_quiz.pdf       # Quiz PDF vuoto
```

### ğŸ“Š **ModalitÃ  2: Valutazione Quiz Esistenti**

**Obiettivo**: Valutare qualitÃ  quiz giÃ  generati con MLflow Judge

**Configurazione** in `main.py`:
```python
def kickoff():
    """Alternative entry point for the flow (CrewAI convention)."""
    plot()
    #main()         # âŒ Commenta questa riga  
    evaluation_flow()  # âœ… Decommenta questa riga
```

**Comando esecuzione**:
```bash
cd quiz_generator
crewai flow kickoff
```

**Processo**:
1. âœ… Carica quiz esistenti da `outputs/questions.json`
2. âœ… Esegue valutazione LLM Judge con MLflow
3. âœ… Genera metriche: answer_relevance, faithfulness, toxicity
4. âœ… Salva risultati in MLflow tracking server

**Accesso risultati**:
```bash
# Visualizza risultati MLflow
open http://127.0.0.1:5001
```

## ğŸ® Guida all'Uso

### **Esperienza Utente Tipica**

```bash
# 1. Avvia il sistema
cd quiz_generator
crewai flow kickoff

# Output interattivo:
ğŸš€ Starting Quiz Generator Flow...

ğŸ“ Available providers:
1. azure
2. databricks
Select provider (1-2): 1

ğŸ“ Available certifications for azure:
1. AI_900
2. AI_102
Select certification (1-2): 2

ğŸ¯ Available topics for azure/AI_102:
1. document_intelligence
2. speech_service
3. foundry_foundry_local
Select topic (1-3): 1

â“ How many questions do you want? (3-10): 7
ğŸ“ Question type? (mixed/true_false/multiple_choice/open_ended): mixed

âœ… User input selection collected successfully!
```

### **Struttura Dataset**

Organizza i tuoi documenti PDF nella cartella `dataset/`:

```
dataset/
â”œâ”€â”€ azure/
â”‚   â”œâ”€â”€ AI_900/
â”‚   â”‚   â”œâ”€â”€ fundamentals.pdf
â”‚   â”‚   â”œâ”€â”€ luis.pdf
â”‚   â”‚   â””â”€â”€ service_azure.pdf
â”‚   â””â”€â”€ AI_102/
â”‚       â”œâ”€â”€ document_intelligence.pdf
â”‚       â”œâ”€â”€ speech_service.pdf
â”‚       â””â”€â”€ foundry_foundry_local.pdf
â””â”€â”€ databricks/
    â”œâ”€â”€ certification_1/
    â””â”€â”€ certification_2/
```

## ğŸ”§ Personalizzazione

### **Configurazione Crews**

Modifica le configurazioni YAML per personalizzare comportamenti:

```bash
# Agenti specializzati
src/quiz_generator/crews/rag_crew/config/agents.yaml
src/quiz_generator/crews/quiz_maker_crew/config/agents.yaml

# Task e workflow
src/quiz_generator/crews/rag_crew/config/tasks.yaml
src/quiz_generator/crews/template_generator_crew/config/tasks.yaml
```

### **Tools Personalizzati**

Estendi le funzionalitÃ  creando nuovi tools:

```python
# Esempio: Custom RAG Tool
from crewai.tools import BaseTool

class CustomRagTool(BaseTool):
    name: str = "Custom RAG Search"
    description: str = "Ricerca personalizzata nel knowledge base"
    
    def _run(self, query: str) -> str:
        # La tua logica personalizzata
        pass
```

## ğŸ§ª Testing

### **Test Suite Completa**

```bash
# Test tutti i componenti
pytest tests/ -v

# Test specifici
python tests/test_azure_ai900.py
python tests/test_complete_flow.py

# Test con coverage
pytest --cov=src tests/
```

## ğŸ“Š Monitoraggio e Analytics

### **MLflow Dashboard**

Accedi al dashboard MLflow per monitorare:

```bash
# Avvia MLflow UI
mlflow ui --host 127.0.0.1 --port 5001

# Accedi via browser
open http://127.0.0.1:5001
```

### **ğŸ“Š Metriche Disponibili**
- **ğŸ“ answer_relevance**: Pertinenza risposta-domanda
- **âœ”ï¸ ari grade level**: LeggibilitÃ  e comprensione delle domande
- **âœ”ï¸ flesch kincaid grade level**: Livello scolastico delle domande
##### mancano le ground truth ancora per queste valutazioni sottostanti
- **âœ… faithfulness**: FedeltÃ  al contesto fornito 
- **ğŸ¯ answer_similarity**: SimilaritÃ  con ground truth
- **âœ”ï¸ answer_correctness**: Correttezza risposta
- **ğŸš« toxicity**: Analisi contenuto tossico

### **Logs e Debugging**

```bash
# Abilita logging verboso
export CREWAI_LOG_LEVEL=DEBUG

# Visualizza flow grafico
python -c "from src.quiz_generator.main import plot; plot()"
```

## ğŸ“ Struttura Output

### **File Generati per Quiz**

```
outputs/
â”œâ”€â”€ {cert}_{topic}_template.md         # Template strutturato
â”œâ”€â”€ {cert}_{topic}_questions.json      # Domande in formato JSON
â”œâ”€â”€ {cert}_{topic}_quiz.md             # Quiz vuoto Markdown
â”œâ”€â”€ {cert}_{topic}_quiz.pdf            # Quiz vuoto PDF
â”œâ”€â”€ {cert}_{topic}_completed_quiz.md   # Quiz completato (se generato)
â”œâ”€â”€ {cert}_{topic}_completed_quiz.pdf  # Quiz completato PDF
â””â”€â”€ {cert}_{topic}_evaluation.md       # Report valutazione (se generato)
```

## ğŸ› Troubleshooting

### **Problemi Comuni**

**ğŸ”§ Errore connessione Qdrant**:
```bash
# Verifica container Docker
docker ps | grep qdrant

# Riavvia se necessario
docker run -p 6333:6333 qdrant/qdrant
```

**ğŸ”‘ Errore Azure OpenAI**:
```bash
# Verifica variabili ambiente
echo $AZURE_OPENAI_API_KEY
echo $AZURE_OPENAI_ENDPOINT

# Testa connessione
curl -H "api-key: $AZURE_OPENAI_API_KEY" "$AZURE_OPENAI_ENDPOINT/openai/models?api-version=2024-02-01"
```

**ğŸ“„ Warning PDF parsing**:
I warning PDF sono automaticamente soppressi nel codice. Se persistono:

```python
# In utils/rag_qdrant_hybrid.py giÃ  implementato:
warnings.filterwarnings("ignore", message=".*Cannot set gray.*")
```

### **Logs Utili**

```bash
# Flow execution logs
python -m src.quiz_generator.main 2>&1 | tee execution.log

# CrewAI debug mode
CREWAI_LOG_LEVEL=DEBUG crewai flow kickoff
```

## ğŸ¤ Contribuire

### **Workflow Contribuzioni**

1. **Fork** del repository
2. **Crea feature branch**: `git checkout -b feature/amazing-feature`
3. **Commit changes**: `git commit -m 'Add amazing feature'`
4. **Push branch**: `git push origin feature/amazing-feature`
5. **Crea Pull Request**

### **Standard Codice**

```bash
# Linting e formatting
black src/ tests/
flake8 src/ tests/
mypy src/

# Test prima di PR
pytest tests/ --cov=src
```

## ğŸ“š Documentazione Avanzata

- ğŸ“š **[FLOW_DOCUMENTATION.md](FLOW_DOCUMENTATION.md)**: Guida utente dettagliata
- ğŸŒ **[Sphinx Docs](quiz_generator/docs/_build/html/index.html)**: API reference
- ğŸ¥ **[CrewAI Documentation](https://docs.crewai.com)**: Framework reference

## ğŸ“„ Licenza

Questo progetto Ã¨ distribuito sotto licenza MIT. Vedi `LICENSE` per dettagli.

## ğŸ™‹â€â™‚ï¸ Supporto

Per supporto, domande o feedback:

- ğŸ“– **Documentazione**: [CrewAI Docs](https://docs.crewai.com)
- ğŸ› **Issues**: [GitHub Repository](https://github.com/joaomdmoura/crewai)
- ğŸ’¬ **Community**: [Discord CrewAI](https://discord.com/invite/X4JWnZnxPb)
- ğŸ¤– **Chat**: [Docs Assistant](https://chatg.pt/DWjSBZn)

---
