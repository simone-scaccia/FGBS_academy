# ğŸ“Š Quiz Generator Flow - Documentazione Completa

## ğŸš€ Panoramica del Sistema

Il **Quiz Generator** Ã¨ una piattaforma avanzata per la generazione automatizzata di quiz educativi che utilizza tecnologie all'avanguardia come **CrewAI Flow**, **Retrieval-Augmented Generation (RAG)**, **Qdrant Vector Database** e **MLflow** per creare un sistema completo di valutazione e apprendimento.

## ğŸ¯ FunzionalitÃ  Principali

### âœ¨ **Generazione Quiz Intelligente**
- ğŸ¤– **RAG-powered**: Utilizza documenti di certificazione per generare domande pertinenti
- ğŸ“Š **Multi-formato**: True/False, Multiple Choice, Open-ended questions
- ğŸ“ **Certificazioni Supportate**: Azure AI-900, AI-102 (futuro Databricks)
- ğŸ“ **Template Dinamici**: Strutture quiz personalizzabili

### ğŸ”„ **Pipeline Completa**
- ğŸ‘¤ **User Experience**: Interfaccia interattiva per selezione contenuti
- ğŸ—„ï¸ **Knowledge Base**: Database vettoriale con documenti di certificazione
- ğŸ“‹ **Template Generator**: Creazione strutture quiz personalizzate
- ğŸ² **Quiz Assembly**: Popolamento template con domande generate
- ğŸ“ **Student Simulation**: Simulazione risposte studente (working in progress)
- ğŸ“Š **Evaluation**: Valutazione automatica qualitÃ  quiz (working in progress)

### ğŸ“ˆ **Tracking & Analytics**
- ğŸ”¬ **MLflow Integration**: Tracking completo esperimenti
- ğŸ§  **LLM Judge**: Valutazione automatica con metriche avanzate
- ğŸ“Š **Performance Metrics**: Analisi qualitÃ  domande e risposte

## ğŸ—ï¸ Architettura del Sistema

### ğŸ“ **Struttura Progetto**
```
quiz_generator/
â”œâ”€â”€ ğŸ src/quiz_generator/
â”‚   â”œâ”€â”€ ğŸŒŠ main.py                     # QuizGeneratorFlow principale
â”‚   â”œâ”€â”€ ğŸ‘¥ crews/                      # Agenti CrewAI specializzati
â”‚   â”‚   â”œâ”€â”€ ğŸ” rag_crew/               # Ricerca e generazione domande
â”‚   â”‚   â”œâ”€â”€ ğŸ“‹ template_generator_crew/ # Creazione template quiz
â”‚   â”‚   â”œâ”€â”€ ğŸ› ï¸ quiz_maker_crew/        # Assemblaggio quiz finale
â”‚   â”‚   â”œâ”€â”€ ğŸ“ quiz_taker_crew/        # Simulazione studente
â”‚   â”‚   â””â”€â”€ ğŸ“Š quiz_evaluator_crew/    # Valutazione automatica
â”‚   â”œâ”€â”€ ğŸ”§ tools/                      # Strumenti specializzati
â”‚   â”‚   â”œâ”€â”€ ğŸ” rag_qdrant_tool.py      # Tool RAG per CrewAI
â”‚   â”‚   â””â”€â”€ ğŸ“„ md_to_pdf_tool.py       # Conversione PDF
â”‚   â”œâ”€â”€ ğŸ› ï¸ utils/                      # Utilities sistema
â”‚   â”‚   â”œâ”€â”€ ğŸ‘¤ user_utils.py           # Interazione utente
â”‚   â”‚   â”œâ”€â”€ ğŸ—„ï¸ database_utils.py       # Gestione database
â”‚   â”‚   â”œâ”€â”€ âš™ï¸ qdrant_utils.py         # Utilities Qdrant
â”‚   â”‚   â””â”€â”€ ğŸ” rag_qdrant_hybrid.py    # Engine RAG
â”‚   â””â”€â”€ ğŸ“š dataset/                    # Knowledge base
â”‚       â”œâ”€â”€ â˜ï¸ azure/                  # Documenti Azure
â”‚       â”‚   â”œâ”€â”€ ğŸ“ AI_900/             # Certificazione AI-900
â”‚       â”‚   â””â”€â”€ ğŸ“ AI_102/             # Certificazione AI-102
â”‚       â””â”€â”€ ğŸ§  databricks/             # Documenti Databricks
â”œâ”€â”€ ğŸ“¤ outputs/                        # File generati
â”œâ”€â”€ ğŸ—„ï¸ qdrant_storage/                 # Database vettoriale
â”œâ”€â”€ ğŸ“š docs/                           # Documentazione Sphinx
â””â”€â”€ ğŸ§ª tests/                          # Test suite
```

## ğŸ”„ Flow di Esecuzione Completo

### **Step 1: ğŸ“ Raccolta Input Utente** `@start()`

**Obiettivo**: Configurazione iniziale del sistema
**File**: `utils/user_utils.py`

**Processo**:
1. **ğŸ” Scansione Dataset**: Analizza struttura cartelle `dataset/`
2. **ğŸ¢ Selezione Provider**: Menu interattivo (azure, databricks, etc.)
3. **ğŸ“ Selezione Certificazione**: Lista certificazioni disponibili
4. **ğŸ¯ Selezione Topic**: Lista argomenti da file PDF
5. **âš™ï¸ Configurazione Quiz**: Numero domande e tipologia

**Output State**:
```python
state.provider = "azure"
state.certification = "AI_102" 
state.topic = "document_intelligence"
state.number_of_questions = 7
state.question_type = "mixed"
```

### **Step 2: ğŸ—„ï¸ Inizializzazione Database** `@listen(collect_user_input)`

**Obiettivo**: Setup knowledge base vettoriale
**File**: `utils/database_utils.py`

**Processo**:
1. **ğŸ“‹ Collection Naming**: `{provider}_{certification}_chunks`
2. **âœ… Check Esistenza**: Verifica collection giÃ  presente
3. **ğŸ“„ Caricamento PDF**: Estrazione testo da `dataset/{provider}/{certification}/`
4. **âœ‚ï¸ Chunking**: Divisione semantica documenti
5. **ğŸ§  Embedding**: Azure OpenAI text-embedding-ada-002
6. **ğŸ’¾ Indicizzazione**: Upsert in Qdrant vector store

**Vantaggi**:
- ğŸ¯ **Collection Isolate**: Una per certificazione
- âš¡ **Performance**: Ricerche mirate
- ğŸ”„ **Riuso**: Skip re-processing se esistente

### **Step 3: ğŸ“‹ Generazione Template** `@listen(initialize_vector_database)`

**Obiettivo**: Creazione struttura quiz personalizzata
**Crew**: **TemplateGeneratorCrew**

**Processo**:
1. **ğŸ¨ Design Template**: Struttura basata su configurazione utente
2. **ğŸ”– Placeholders**: Segnaposto per popolamento automatico
   - `[TF_Question_X]` per True/False
   - `[MC_Question_X]` per Multiple Choice
   - `[Open_Question_X]` per domande aperte
3. **ğŸ“ Markdown Generation**: Template formattato professionalmente

**Output**: `outputs/{certification}_{topic}_template.md`

### **Step 4: ğŸ” Generazione Domande RAG** `@listen(generate_quiz_template)`

**Obiettivo**: Creazione domande intelligenti con RAG
**Crew**: **RagCrew**

**Agenti**:
- **ğŸ•µï¸ Researcher**: Ricerca contestuale nel database
- **ğŸ“Š Reporting Analyst**: Compilazione quiz strutturato

**Processo**:
1. **ğŸ” RAG Search**: Query mirate nel vector database
2. **ğŸ¯ Context Retrieval**: Estrazione passaggi rilevanti
3. **ğŸ¤– Question Generation**: LLM genera domande da contesto
4. **ğŸ“ JSON Structure**: Output strutturato per popolamento

**Configuration**:
```python
rag_crew = RagCrew(provider=provider, certification=certification)
inputs = {
    "topic": topic,
    "number_of_questions": 7,
    "question_type": "mixed"
}
```

**Output**: `outputs/{certification}_{topic}_questions.json`

### **Step 5: ğŸ› ï¸ Assemblaggio Quiz Finale** `@listen(generate_quiz_with_rag_crew)`

**Obiettivo**: Popolamento template con domande
**Crew**: **QuizMakerCrew**

**Processo**:
1. **ğŸ”„ Template Loading**: Carica template generato
2. **ğŸ“Š JSON Parsing**: Analizza domande strutturate
3. **ğŸ”§ Placeholder Replacement**: Sostituisce segnaposto con contenuto
4. **ğŸ“„ Markdown Generation**: Quiz finale formattato
5. **ğŸ–¨ï¸ PDF Export**: Conversione in PDF per distribuzione

**CRITICO**: Quiz **VUOTO** - nessuna risposta pre-compilata per domande aperte

**Output**: 
- `outputs/{certification}_{topic}_quiz.md` (quiz vuoto)
- `outputs/{certification}_{topic}_quiz.pdf` (PDF vuoto)

## Simulation Student and Evaluation Crews are working in progress
#### **Step 6: ğŸ“ Simulazione Studente** `@listen(create_final_quiz)` [Opzionale]

**Obiettivo**: Completamento quiz da parte di studente simulato
**Crew**: **QuizTakerCrew**

**Processo**:
1. **ğŸ§  LLM-Only Knowledge**: Nessun accesso a RAG o ground truth
2. **âœï¸ Quiz Completion**: Risposte basate su conoscenza LLM
3. **ğŸ“ Answer Formatting**: Formattazione risposte corretta
4. **ğŸ“„ PDF Generation**: Quiz completato separato

**Output**:
- `outputs/{certification}_{topic}_completed_quiz.md`
- `outputs/{certification}_{topic}_completed_quiz.pdf`

### **Step 7: ğŸ“Š Valutazione Automatica** `@listen(take_quiz)` [Opzionale]

**Obiettivo**: Analisi qualitÃ  quiz e risposte
**Crew**: **QuizEvaluatorCrew**

**Processo**:
1. **ğŸ” Content Analysis**: Analisi domande e risposte
2. **ğŸ“Š Quality Metrics**: DifficoltÃ , chiarezza, pertinenza
3. **ğŸ“ˆ Performance Report**: Report dettagliato valutazione

**Output**: `outputs/{certification}_{topic}_evaluation.md`

### **Step 8: âœ… Finalizzazione** `@listen(create_final_quiz)`

**Obiettivo**: Summary e cleanup
**Processo**:
1. **ğŸ“‹ Status Report**: Stato finale di tutti gli step
2. **ğŸ“ File Summary**: Lista file generati
3. **ğŸš¨ Error Handling**: Report errori eventuali
4. **ğŸ§¹ Cleanup**: Chiusura risorse

## ğŸ”§ Configurazione Tecnologica

### **Environment Variables** (.env)
```bash
# ğŸ¤– Azure OpenAI Configuration
AZURE_OPENAI_API_KEY=your_api_key_here
AZURE_OPENAI_API_VERSION=2025-01-01-preview
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/
MODEL=gpt-4o
EMB_MODEL_NAME=text-embedding-ada-002

# ğŸ—„ï¸ Qdrant Vector Database
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=optional_api_key

# ğŸ“Š MLflow Tracking
MLFLOW_TRACKING_URI=http://127.0.0.1:5001
```

### **Dipendenze Principali** (pyproject.toml)
```toml
dependencies = [
    "crewai[tools]>=0.177.0,<1.0.0",
    "langchain>=0.3.27",
    "langchain-openai>=0.2.14", 
    "qdrant-client>=1.15.1",
    "mlflow>=3.3.2",
    "pymupdf>=1.26.4",
    "markdown-pdf>=1.9",
    "pytest>=8.4.2"
]
```

## ğŸš€ Guida all'Uso

### **ğŸ”§ Installazione**
```bash
# Clone repository
git clone <repository_url>
cd quiz_generator

# Install dependencies
pip install -e .

# Setup environment
cp .env.example .env
# Edit .env with your credentials
```

### **ğŸ³ Setup Infrastruttura**
```bash
# Start Qdrant vector database
docker run -p 6333:6333 qdrant/qdrant

# Start MLflow tracking server
mlflow server --host 127.0.0.1 --port 5001
```

### **â–¶ï¸ Esecuzione**
```bash
# Metodo principale
python -m src.quiz_generator.main

# Metodo CrewAI CLI
crewai flow kickoff

# Visualizzazione flow
python -c "from src.quiz_generator.main import plot; plot()"
```

### **ğŸ‘¤ Esperienza Utente**
```
ğŸš€ Starting Quiz Generator Flow...

ğŸ“ Available providers:
1. azure
2. databricks
Select provider (1-2): 1

ğŸ“ Available certifications for azure:
1. AI_900
2. AI_102  
Select certification (1-2): 2

ğŸ¯ Available topics for azure/AI_102:
1. document_intelligence
2. speech_service
3. foundry_foundry_local
Select topic (1-3): 1

â“ How many questions do you want? (3-10): 7
ğŸ“ Question type? (mixed/true_false/multiple_choice/open_ended): mixed

âœ… User input selection collected successfully!
```

## ğŸ“Š Output Files Generati

### **ğŸ“ Struttura Output**
```
outputs/
â”œâ”€â”€ ğŸ“‹ AI_102_document_intelligence_template.md      # Template quiz
â”œâ”€â”€ ğŸ“Š AI_102_document_intelligence_questions.json   # Domande JSON
â”œâ”€â”€ ğŸ“ AI_102_document_intelligence_quiz.md          # Quiz vuoto Markdown
â”œâ”€â”€ ğŸ“„ AI_102_document_intelligence_quiz.pdf         # Quiz vuoto PDF
â”œâ”€â”€ âœï¸ AI_102_document_intelligence_completed_quiz.md # Quiz completato
â”œâ”€â”€ ğŸ“„ AI_102_document_intelligence_completed_quiz.pdf # Quiz completato PDF
â””â”€â”€ ğŸ“Š AI_102_document_intelligence_evaluation.md    # Report valutazione
```

### **ğŸ“‹ Esempio Template**
```markdown
# **Azure - AI_102**

## True/False Questions
1. **[TF_Question_1]**  
  [] True  
  [] False  

## Multiple Choice Questions  
2. **[MC_Question_1]**  
  A) [MC_Option_A_1]  
  B) [MC_Option_B_1]  
  C) [MC_Option_C_1]  
  D) [MC_Option_D_1]  

## Short Open Questions
3. **[Open_Question_1]**  
  ________________________________________________________
```

### **ğŸ“Š Esempio JSON Questions**
```json
{
  "quiz_info": {
    "topic": "Document Intelligence",
    "certification": "AI_102",
    "provider": "Azure",
    "generated_at": "2025-01-09T10:30:00Z"
  },
  "questions": [
    {
      "id": 1,
      "type": "true_false",
      "question": "Document Intelligence can process only structured documents.",
      "answer": false,
      "explanation": "Document Intelligence can handle both structured and unstructured documents..."
    },
    {
      "id": 2, 
      "type": "multiple_choice",
      "question": "Which service is used for custom document processing?",
      "options": {
        "A": "Form Recognizer",
        "B": "Document Intelligence", 
        "C": "Cognitive Search",
        "D": "Text Analytics"
      },
      "answer": "B",
      "explanation": "Document Intelligence is the updated name for Form Recognizer..."
    }
  ]
}
```

### **ğŸ¯ Test Patterns**
```python
def test_quiz_generation():
    """Test generazione quiz AI-900 completa"""
    flow = QuizGeneratorFlow()
    flow.state.provider = "azure"
    flow.state.certification = "AI_900"
    flow.state.topic = "luis"
    
    # Test database initialization
    flow.initialize_vector_database()
    assert flow.state.database_initialized
    
    # Test quiz generation
    flow.generate_quiz_with_rag_crew()
    assert flow.state.quiz_generated
```

## ğŸ“Š MLflow Integration & Analytics

### **ğŸ”¬ Experiment Tracking**
```python
# Configurazione automatica
mlflow.set_tracking_uri("http://127.0.0.1:5001")
mlflow.autolog()
mlflow.set_experiment("FlowGruppo2")
```

### **ğŸ§  LLM Judge Evaluation**
```python
def evaluation_flow():
    """Valutazione automatica con MLflow"""
    eval_metrics = _run_llm_judge_mlflow(
        user_query=question_text,
        prediction=answer,
        context=context,           # opzionale
        ground_truth=ground_truth  # opzionale
    )
    mlflow.log_dict(eval_metrics, "eval_metrics_snapshot.json")
```

### **ğŸ“Š Metriche Disponibili**
- **ğŸ“ answer_relevance**: Pertinenza risposta-domanda
- **âœ”ï¸ ari grade level**: LeggibilitÃ  e comprensione delle domande
- **âœ”ï¸ flesch kincaid grade level**: Livello scolastico delle domande
##### mancano le ground truth ancora per queste valutazioni sottostanti
- **âœ… faithfulness**: FedeltÃ  al contesto fornito 
- **ğŸ¯ answer_similarity**: SimilaritÃ  con ground truth
- **âœ”ï¸ answer_correctness**: Correttezza risposta
- **ğŸš« toxicity**: Analisi contenuto tossico

## ğŸ” Security & Best Practices

### **ğŸ”‘ Gestione Credenziali**
- âœ… Environment variables per API keys
- âœ… Nessuna persistenza credenziali in codice
- âœ… Rate limiting per API calls
- âœ… Error handling robusto

### **ğŸ›¡ï¸ Data Privacy**
- âœ… Dataset locale - nessun upload cloud
- âœ… Embedding Azure dedicato
- âœ… Vector database locale (Qdrant)
- âœ… Controllo completo sui dati

### **âš¡ Performance Optimization**
- âœ… Collection separate per certificazione
- âœ… Batch processing embedding
- âœ… Connection pooling database
- âœ… Chunking ottimizzato memoria

## ğŸ› Troubleshooting

### **âŒ Errori Comuni**

**ğŸ”§ Database Connection**
```bash
# Start Qdrant se non running
docker run -p 6333:6333 qdrant/qdrant
```

**ğŸ”‘ Azure OpenAI Configuration**
```bash
# Verifica variabili ambiente
echo $AZURE_OPENAI_API_KEY
echo $AZURE_OPENAI_ENDPOINT
```

**ğŸ“„ PDF Processing Warnings**
```python
# Warnings automaticamente soppressi in load_pdf()
warnings.filterwarnings("ignore", message=".*Cannot set gray.*")
```

### **ğŸ” Debug Flow**
```python
# Enable verbose logging
import logging
logging.basicConfig(level=logging.INFO)

# Check state progression
print(f"State: {flow.state}")
```

## ğŸš€ Roadmap & Estensioni Future

### **ğŸ¯ FunzionalitÃ  Pianificate**
- ğŸŒ **Multi-lingua**: Supporto quiz in piÃ¹ lingue
- ğŸ¨ **UI Web**: Interfaccia web per utenti non-tecnici
- ğŸ“± **API REST**: Endpoints per integrazione externa
- ğŸ“ **Adaptive Learning**: Quiz personalizzati su performance
- ğŸ“Š **Advanced Analytics**: Dashboard metriche dettagliate

### **ğŸ”§ Miglioramenti Tecnici**
- âš¡ **Parallel Processing**: Generazione parallela domande
- ğŸ”„ **Incremental Updates**: Update incrementali database
- ğŸ¯ **Smart Chunking**: Chunking semantico avanzato

### **ğŸ¤ Integrazioni**
- ğŸ“± **Mobile Apps**: App mobile per quiz taking

Il Quiz Generator rappresenta una soluzione completa e scalabile per la generazione automatizzata di quiz educativi, combinando le migliori pratiche di AI, RAG e software engineering in un sistema robusto e user-friendly.
